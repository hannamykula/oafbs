{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when in Google Colab\n",
    "! git init\n",
    "! git remote add origin https://github.com/hannamykula/oafbs.git\n",
    "! git fetch\n",
    "! git checkout -t origin/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tslearn\n",
    "! pip install scikit-multiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.process import read_and_split_data, subsample_features\n",
    "from src.model import train_candidates, cluster_predictions, compute_cluster_representatives, root_mean_square_error, plot_clustering, get_best_num_of_clusters, save_validation_predictions\n",
    "from src.drift import PageHinkley, DataDrift\n",
    "from src.predict import predict_n_steps_for_ensemble, predict_one_step_for_ensemble, get_weights, final_prediction_ensemble\n",
    "import os\n",
    "import pandas as pd\n",
    "from config import EXPERIMENT_NAME, VALIDATION_WINDOW_SIZE, WEIGHTS_WINDOW_SIZE, EVALUATION_WINDOW, TARGET_INDEX, SUBSET_SIZE, K, MODEL\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q --show-progress -P data/{EXPERIMENT_NAME}/ https://www.dropbox.com/s/ga07hldz2rizkuu/NEW-DATA-1.T15-PREPROCESSED.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = read_and_split_data(EXPERIMENT_NAME + '/NEW-DATA-1.T15-PREPROCESSED.csv', val_size=VALIDATION_WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "target_index = TARGET_INDEX\n",
    "subset_size = SUBSET_SIZE\n",
    "k = K\n",
    "model = MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_subsets = subsample_features(train, target_index, subset_size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error for model 1 is 0.03315993508413894.\n",
      "Validation error for model 2 is 0.035828810072875854.\n",
      "Validation error for model 3 is 0.03580723946696871.\n",
      "Validation error for model 4 is 0.007776070689147423.\n",
      "Validation error for model 5 is 0.022095195883565538.\n",
      "Validation error for model 6 is 0.01586920853677343.\n",
      "Validation error for model 7 is 0.009109451261225658.\n",
      "Validation error for model 8 is 0.02626317780374889.\n",
      "Validation error for model 9 is 0.016199688278780263.\n",
      "Validation error for model 10 is 0.00777607068914739.\n"
     ]
    }
   ],
   "source": [
    "train_candidates(train, val, target_index, sample_subsets, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_FILENAME = os.path.join(os.getcwd(), 'experiments', EXPERIMENT_NAME, 'validation_predictions_init.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pred = pd.read_csv(VALIDATION_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = get_best_num_of_clusters(validation_pred.transpose(), range(2,10))\n",
    "cluster_result, cluster_centers = cluster_predictions(validation_pred.transpose(), num_clusters)\n",
    "ensemble = compute_cluster_representatives(cluster_result, cluster_centers, validation_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = PageHinkley(delta=0.005, threshold=0.025)\n",
    "hoeffding = DataDrift(threshold=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_indices = list(map(str, list(range(1, len(sample_subsets)+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble(X, running_version_name):\n",
    "    val_predictions = predict_n_steps_for_ensemble(all_model_indices, X, sample_subsets)\n",
    "    val_predictions = pd.DataFrame(val_predictions)\n",
    "    val_predictions.columns = range(1, len(val_predictions.columns)+1)\n",
    "\n",
    "    cluster_result, cluster_centers = cluster_predictions(val_predictions, num_clusters)\n",
    "    ensemble = compute_cluster_representatives(cluster_result, cluster_centers, val_predictions.transpose())\n",
    "\n",
    "    return list(map(str, ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.concat([val, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-5b7b4f159440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_window\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_window\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_subsets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpred_at_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_prediction_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_subsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtest_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_at_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mEVALUATION_WINDOW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hanna\\Documents\\Repo\\oafbs\\src\\predict.py\u001b[0m in \u001b[0;36mfinal_prediction_ensemble\u001b[1;34m(ensemble, X, sample_subsets, weights)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mweighted_average\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweighted_average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "start_index = 0\n",
    "test_predictions = []\n",
    "evaluation_sliding_window_start = 0\n",
    "version = 1\n",
    "while start_index < (len(test) - WEIGHTS_WINDOW_SIZE):\n",
    "    end_index = start_index + WEIGHTS_WINDOW_SIZE\n",
    "    X_window = test.iloc[start_index:end_index, ]\n",
    "    y_window = test.iloc[start_index:end_index, target_index]\n",
    "    X = test.iloc[end_index, ]\n",
    "    print(start_index)\n",
    "    weights = get_weights(ensemble, X_window, y_window, sample_subsets)\n",
    "    pred_at_t = final_prediction_ensemble(ensemble, X, sample_subsets, weights)\n",
    "    test_predictions.append(pred_at_t)\n",
    "    if(len(test_predictions) >= EVALUATION_WINDOW):\n",
    "        X = test.iloc[WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start:WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start+EVALUATION_WINDOW, test.columns!=test.columns[target_index]]\n",
    "        y = test.iloc[WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start:WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start+EVALUATION_WINDOW, target_index]\n",
    "        y_predicted = test_predictions[evaluation_sliding_window_start:evaluation_sliding_window_start+EVALUATION_WINDOW]\n",
    "        error = root_mean_square_error(y.to_numpy(), y_predicted)\n",
    "        print(f'Error for window [{WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start}:{WEIGHTS_WINDOW_SIZE+evaluation_sliding_window_start+EVALUATION_WINDOW}] is {error}')\n",
    "        ph.add_element(error)\n",
    "        print(f'Difference: {ph.sum - ph.minimum}')\n",
    "\n",
    "        glob_min = hoeffding.min\n",
    "        hoeffding.add_element(X, y)\n",
    "        print(f'Hoeffding global minimum: {glob_min}. Latest minimum: {hoeffding.min2}. Sample count: {hoeffding.sample_count}')\n",
    "        if ph.detected_change():\n",
    "            print('Change in error detected.')\n",
    "        if hoeffding.detected_change():\n",
    "            print('Change in data detected')\n",
    "        if ph.detected_change() | hoeffding.detected_change():\n",
    "            X_val = validation.iloc[end_index:end_index + VALIDATION_WINDOW_SIZE, ]\n",
    "            ensemble = compute_ensemble(X_val, version)\n",
    "            version += 1\n",
    "        evaluation_sliding_window_start += 1\n",
    "    start_index = start_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01919480659591487"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_square_error(test.iloc[WEIGHTS_WINDOW_SIZE:, target_index].to_numpy(), test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "save_name = EXPERIMENT_NAME + '_' + MODEL + '_k' + K + '_results.csv'\n",
    "path = F'/content/drive/MyDrive/Colab Notebooks/oafbs_results/{save_name}'\n",
    "test_predictions.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
